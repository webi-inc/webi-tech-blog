---
title: "딥페이크 생성 속도가 팩트체크를 앞지른다: 디지털 포렌식 전문가 Hany Farid의 경고"
description: "UC 버클리의 디지털 포렌식 연구자 Hany Farid는 생성형 AI로 인해 딥페이크 생성 속도가 팩트체크를 압도하고 있으며, 콘텐츠가 아닌 인프라를 타겟으로 한 규제가 필요하다고 강조합니다."
date: 2026-02-19 05:00:06 +0900
categories: ['Security', 'Infosec']
tags: ['딥페이크', '생성형AI', '디지털포렌식', 'HanyFarid', '비동의음란물', '보안', 'GetReal']
image:
  path: "/assets/img/2026-02-18-deepfakes-are-getting-faster-than-fact-checks-says-digital-forensics-expert-hany-farid-7977.jpg"
  alt: "딥페이크와 디지털 포렌식 기술을 시각화한 이미지"
published: true
---

## 3줄 요약
- 생성형 AI로 인해 딥페이크 제작이 빠르고 저렴해져 팩트체크보다 빠르게 확산되고 있습니다.
- UC 버클리의 Hany Farid 교수는 콘텐츠 제거가 아닌 호스팅, 앱스토어, 결제 시스템 등 인프라 규제가 필요하다고 주장합니다.
- GetReal은 디지털 포렌식 기반으로 실시간 스트림에서 딥페이크를 탐지하는 기술을 개발 중입니다.

## 📌 주요 내용

### 딥페이크가 신뢰 인프라를 위협하는 방식

캘리포니아 대학교 버클리의 디지털 포렌식 연구자 Hany Farid는 딥페이크 기술이 현대 사회의 신뢰 구조를 근본적으로 위협하고 있다고 경고합니다. 생성형 AI의 등장으로 딥페이크 제작이 과거에는 시간과 기술, 전문 도구가 필요했던 작업에서 누구나 즉시 생성할 수 있는 수준으로 변화했습니다.

Farid 교수는 "신뢰 인프라"를 세 가지 층위로 설명합니다. 첫째, 소셜 미디어에서 보는 모든 것을 어떻게 신뢰할 것인가의 문제입니다. 둘째, 법정에서 증거를 어떻게 신뢰할 것인가입니다. 그는 "변호사들이 거의 매일 '이 녹음, 이 이미지, 이 CCTV 영상을 받았는데 이제 어떻게 해야 하나요?'라고 묻습니다"라고 말합니다. 셋째, 자율주행차부터 작성하는 코드까지 AI가 완전히 통합될 때 이러한 시스템을 어떻게 신뢰할 것인가의 문제입니다.

### 생성형 AI에 대한 가장 큰 오해

Farid는 사람들이 생성형 AI를 "AI"라고 부르는 것 자체가 가장 큰 오해라고 지적합니다. 그는 이를 "토큰 텀블러(token tumbler)"라고 부르는 것을 선호합니다. "엄청난 양의 텍스트를 가져와서 단어를 숫자 토큰으로 압축한 다음 정교한 자동완성을 수행하는 것입니다. '이런 토큰들을 봤으니 다음 토큰은 무엇인가?' 하는 식이죠. 이것은 인공적이지만 확실히 지능은 아닙니다."

더 중요한 점은 대부분의 "지능"이 컴퓨터가 아니라 실제로는 인간에게서 나온다는 것입니다. 데이터를 스크래핑하고 토큰 텀블러를 구축하는 것만으로는 ChatGPT가 되지 않습니다. ChatGPT로 가는 방법은 수많은 인간을 투입하여 질문과 답변에 인간 주석을 달고 "이것은 좋은 답변, 저것은 나쁜 답변"이라고 말하는 것입니다. 이것이 바로 미세 조정과 강화 학습이라고 불리는 것입니다.

### 현재 가장 심각한 피해 사례들

Farid가 지적하는 가장 심각한 피해는 다음과 같습니다:

**비동의 음란물(NCII)과 아동 성 착취**: 초기 딥페이크는 주로 비동의 성적 이미지 도구로 확산되었습니다. 현재는 아동 성 착취, 성적 협박, 그리고 챗봇이 아이들에게 자살을 권유하는 사례까지 발생하고 있습니다.

**사기 행위의 급증**: 음성 복제 기술을 이용한 개인 대상 사기가 급증하고 있습니다. 할머니가 손주로 가장한 전화를 받거나, CEO가 가짜 전화를 받는 사례가 대표적입니다.

**정보 생태계의 오염**: 허위 정보 캠페인이 정보 생태계 전체를 오염시키고 있습니다.

**교육 시스템의 혼란**: Farid는 대학 교수로서 "AI를 사용하지 않는 학생은 단 한 명도 없습니다"라고 말하며, 교육 방식의 근본적인 재고가 필요하다고 강조합니다.

### 해시 매칭의 한계와 대안

Microsoft 팀과 함께 아동 성 착취 이미지 식별을 위한 PhotoDNA를 개발했던 Farid는 해시 매칭 기술의 한계를 인정합니다. 실제 아동이 착취당한 이미지의 경우 동일한 이미지와 동영상이 반복적으로 유포되기 때문에 해시 매칭이 효과적입니다.

그러나 현재의 NCII는 AI로 생성되기 때문에 대량 제작이 가능합니다. "이 이미지를 잡아도 다음 30초 안에 100개를 더 만들 수 있습니다. 해시 매칭은 특정 수준까지만 효과가 있고, 사람들이 이제 너무 빠르게 만들 수 있기 때문에 따라잡을 수 없을 것입니다."

### 입법자들이 멈춰야 할 것과 해야 할 것

Farid는 TAKE IT DOWN Act의 초기 버전 작업에 참여했지만, 최종 법안은 "형편없는 법"이 되었다고 비판합니다.

**문제점들**:
- Nudify 앱 제작자에게 책임을 묻지 않습니다
- 48시간 삭제 기한은 터무니없습니다. "인터넷에서는 모든 일이 첫 90초 안에 일어나기 때문입니다"
- 허위 신고에 대한 처벌이 없어 무기화될 가능성이 있습니다

**해결책**: 콘텐츠가 아닌 인프라를 타겟으로 해야 합니다. "바퀴벌레가 1,000마리 있다면 둥지를 찾아 불태워야 합니다." 구체적으로는 콘텐츠를 호스팅하는 수십 개의 회사들, Apple과 Google 스토어, 수익화를 가능하게 하는 Visa, MasterCard, PayPal 시스템을 규제해야 합니다.

### GetReal의 실시간 딥페이크 탐지 기술

Farid가 설립한 GetReal은 2022년 파일 기반 분석으로 시작했지만, Zoom과 Teams 통화에서 실시간으로 다른 사람을 사칭하는 공격이 증가하면서 실시간 스트림 분석으로 확장했습니다.

GetReal은 디지털 포렌식 우선 접근 방식을 취합니다. "우리는 이 하나의 Sora 비디오뿐만 아니라 비디오 생성기, 음성 생성기, 이미지 생성기 전반에 걸쳐 볼 수 있는 아티팩트가 무엇인지 묻습니다." 파일이 재압축되고 크기가 조정되고 조작된 후에도 측정할 수 있는 포렌식 흔적을 찾아 탐지 기술을 구축합니다.

법정에서 증언할 때 Farid는 "컴퓨터가 그렇게 말했기 때문에 이것이 가짜라고 생각합니다"라고 말하지 않습니다. 대신 "우리는 이러한 특정 아티팩트를 찾고, 보세요, 그 아티팩트를 찾았습니다"라고 설명합니다.

### 플랫폼 보호를 위한 가장 빠른 변화

Farid가 가장 먼저 바꾸고 싶은 것은 책임 소재를 명확히 하는 것입니다. "피해를 일으키는 제품을 만들고, 그 사실을 알았거나 알았어야 했다면, 물리적 세계에서 하는 방식대로 소송을 걸어 암흑기로 돌려보낼 것입니다."

Section 230(사용자 게시 콘텐츠에 대한 플랫폼 책임을 면제하는 법)이 생성형 AI를 보호하지 않을 가능성이 높다고 주장합니다. "생성형 AI는 제3자 콘텐츠가 아닙니다. 그것은 당신의 콘텐츠입니다. 당신이 만든 것입니다. Nudify라는 앱을 만든 건 당신입니다. 아이에게 자살하라고 말하고 부모에게 그 대화를 말하지 말라고 한 것은 당신의 챗봇입니다."

또한 호주가 시행한 16세 미만 아동에 대한 소셜 미디어 금지를 긍정적인 보호 조치로 평가합니다. "아이들을 위한 소셜 미디어는 실험이었습니다. 작동하지 않았습니다. 재앙입니다. 증거는 압도적입니다."

### 음성 복제 사기에 대한 실용적 조언

Farid는 아내와 안전 단어(safety word)를 사용한다고 말합니다. "디지털 문제에 대한 아날로그 솔루션입니다. 로우테크죠."

실제로 그는 음성 복제 공격을 받은 경험이 있습니다. 매우 민감한 사건을 함께 작업하던 변호사가 그의 번호에서 그의 목소리로 사건에 대해 이야기하는 전화를 받았습니다. 변호사가 의심을 품고 다시 전화했을 때 Farid는 무슨 일인지 몰랐고, 둘은 그 사건의 나머지 기간 동안 암호를 만들었습니다.

가족들에게는 항상 인식하고 있으라고 조언합니다. "새벽 2시에 아들로부터 무언가 끔찍한 말을 하는 전화를 받게 될 것입니다. 그러니 끊고 다시 전화하세요."

## 👨‍💻 개발자에게 미치는 영향

### 신뢰 가능한 시스템 구축의 새로운 요구사항

개발자들은 이제 단순히 기능을 구현하는 것을 넘어 진위 검증 시스템을 설계 단계부터 고려해야 합니다. Farid가 제시하는 신뢰 가능한 인프라의 핵심 요구사항은 다음과 같습니다:

**낮은 오탐률(False Positive)**: "매번 통화할 때마다 기술이 '에릭이 가짜, Hany가 가짜'라고 한다면 그냥 무시하게 될 것입니다. 길거리의 자동차 경보처럼요." 시스템의 신뢰성을 유지하려면 오탐률을 극도로 낮게 유지해야 합니다.

**실시간 처리 속도**: 특히 스트림에서는 빨라야 합니다. 10분을 기다릴 수 없습니다. 실시간 영상 통화 환경에서 5초 이내에 수백 프레임을 분석할 수 있어야 합니다.

**설명 가능성(Explainability)**: 법정이나 국가 안보 기관에서 "우리가 그렇게 말했기 때문에 가짜입니다"라고 말할 수 없습니다. 탐지 알고리즘이 어떤 아티팩트를 기반으로 판단했는지 명확히 설명할 수 있어야 합니다.

### AI 통합 제품의 책임 문제

Section 230 보호가 생성형 AI에는 적용되지 않을 가능성이 높다는 Farid의 지적은 AI 기능을 통합하는 개발자들에게 중요한 의미를 갖습니다. 사용자 생성 콘텐츠가 아닌 AI 생성 콘텐츠는 개발사의 제품으로 간주될 수 있으며, 이는 법적 책임의 새로운 패러다임을 의미합니다.

개발자들은 자신들이 만드는 AI 도구가 어떻게 악용될 수 있는지 설계 단계에서부터 고려하고, 적절한 안전장치를 구현해야 합니다. 특히 음성 복제, 이미지 생성, 비디오 합성 기능을 제공하는 제품의 경우 더욱 신중한 접근이 필요합니다.

### 디지털 포렌식 기술의 미래

GetReal의 접근 방식은 개발자들에게 중요한 통찰을 제공합니다. 파일 기반 분석에서 실시간 스트림 분석으로의 전환은 기술 발전 방향을 보여줍니다. 역설적으로 실시간 스트림이 파일보다 탐지하기 쉬울 수 있는데, 이는 공격자가 실시간으로 가짜를 생성해야 하는 반면 탐지 시스템은 수백 프레임을 분석할 시간이 있기 때문입니다.

개발자들은 압축, 크기 조정, 재인코딩 등의 변환 과정을 거친 후에도 남아있는 디지털 아티팩트를 식별하고 추적하는 기술에 더 많은 관심을 기울여야 합니다. 이는 향후 신뢰 가능한 디지털 증거 시스템 구축의 핵심이 될 것입니다.

> <a href="https://www.scientificamerican.com/article/deepfakes-are-getting-faster-than-fact-checks-says-digital-forensics-expert/" target="_blank" rel="noopener noreferrer">원문 기사 보기</a>