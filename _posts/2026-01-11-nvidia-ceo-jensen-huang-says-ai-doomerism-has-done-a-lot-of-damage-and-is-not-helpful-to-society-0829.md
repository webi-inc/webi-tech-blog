---
title: "ollama 0.14: AI가 Bash 명령어를 실행할 수 있는 실험적 기능 도입"
description: "ollama 0.14-rc2가 출시되어 LLM이 시스템에서 Bash 명령어를 실행할 수 있는 실험적 에이전트 루프 기능을 도입했습니다. 대화형 승인 UI와 안전 장치를 통해 AI의 명령 실행을 제어할 수 있습니다."
date: 2026-01-12 05:00:42 +0900
categories: ['Trend', 'AI Industry']
tags: [ollama, LLM, Bash, AI Agent, 명령어실행, 로컬AI, 머신러닝, MLX]
image:
  path: "/assets/img/2026-01-11-nvidia-ceo-jensen-huang-says-ai-doomerism-has-done-a-lot-of-damage-and-is-not-helpful-to-society-0829.jpg"
  alt: "ollama의 Bash 명령어 실행 기능을 보여주는 이미지"
published: true
---

## 3줄 요약
- ollama 0.14-rc2가 LLM이 시스템에서 Bash 명령어를 실행할 수 있는 실험적 에이전트 루프 기능을 도입했습니다.
- 대화형 승인 UI, 안전 명령어 허용 목록, 위험 명령어 차단 목록 등의 안전 장치가 포함되어 있습니다.
- MLX 기반의 이미지 생성 지원과 AMD 내장 그래픽의 VRAM 측정 개선 등 다양한 기능이 추가되었습니다.

## 📌 주요 내용

### ollama 0.14의 실험적 Bash 명령어 실행 기능

ollama 0.14-rc2 버전이 출시되면서 AI와 LLM이 로컬 시스템에서 Bash 명령어를 실행할 수 있는 획기적인 기능이 도입되었습니다. 이 기능은 `ollama run --experimental` 명령어를 통해 활성화할 수 있는 옵트인 방식으로 제공되며, LLM이 Bash와 웹 검색 같은 도구를 활용할 수 있는 에이전트 루프를 실행합니다.

이 새로운 기능은 일부 사용자들에게 우려를 불러일으킬 수 있지만, ollama 팀은 여러 안전 장치를 마련했습니다. LLM이 시스템에서 무분별하게 명령어를 실행하지 못하도록 대화형 승인 사용자 인터페이스를 제공합니다.

### 다층 보안 메커니즘

ollama 0.14의 Bash 실행 기능에는 다음과 같은 보안 메커니즘이 구현되어 있습니다:

- **자동 허용 목록**: `npm run`, `pwd`, `git status` 등 안전한 명령어들은 자동으로 허용됩니다.
- **차단 목록**: `sudo`, `rm -rf` 같은 위험한 명령어는 자동으로 차단됩니다.
- **대화형 승인 UI**: 화살표 키로 탐색할 수 있는 승인 인터페이스를 제공합니다.
- **디렉토리 기반 허용**: 특정 경로에 대한 명령어를 승인하면 해당 경로의 모든 하위 항목에 대해 자동으로 허용됩니다 (예: `cat src/`를 승인하면 `cat src/*`가 허용됨).
- **경로 외부 접근 경고**: 프로젝트 디렉토리 외부의 경로를 대상으로 하는 명령어에 대해서는 경고 박스가 표시됩니다.

### 핵심 기능 상세

이번 업데이트에서 병합된 merge request에 따르면 다음과 같은 기능들이 포함되어 있습니다:

- **내장 도구**: Bash 명령어 실행, ollama API를 통한 웹 검색
- **접두사 기반 허용 목록**: 승인된 디렉토리에 대한 접두사 기반 명령어 허용
- **자격 증명 접근 차단**: 시스템 자격 증명에 접근하는 패턴을 차단합니다

### 추가 개선 사항

ollama 0.14-rc2에는 Bash 기능 외에도 다음과 같은 개선 사항이 포함되어 있습니다:

- **Anthropic API 호환성 향상**: Anthropic의 API와의 호환성이 개선되었습니다.
- **AMD 내장 그래픽 VRAM 측정 정확도 개선**: AMD 통합 그래픽의 비디오 RAM 측정이 더욱 정확해졌습니다.
- **Swift 코드 하이라이팅 지원**: Swift 소스 코드 구문 강조 기능이 추가되었습니다.
- **Zstd 압축 사용**: Linux 설치 번들에 Zstd 압축을 사용하여 파일 크기를 최적화했습니다.
- **MLX 기반 이미지 생성 실험적 지원**: Z-Image 모델을 사용한 이미지 생성 기능이 실험적으로 추가되었습니다.

### 이미지 생성 기능의 현재 상태

어제 병합된 이미지 생성 관련 merge request에 따르면, 이 기능은 아직 초기 단계에 있습니다:

> "이 PR은 MLX 기반 러너로 구동되는 Z-Image 모델을 사용한 실험적 이미지 생성 지원을 추가합니다. 이것은 최적화되지 않았습니다. VRAM 사용량과 생성 속도 모두 향후 반복 작업에서 크게 개선될 것입니다. 이것은 반복 작업을 위한 시작점입니다."

## 👨‍💻 개발자에게 미치는 영향

### 로컬 AI 개발 워크플로우의 혁신

ollama 0.14의 Bash 명령어 실행 기능은 로컬 AI 개발 워크플로우를 크게 변화시킬 수 있습니다. 개발자들은 LLM을 활용하여 자동화된 스크립트 실행, 파일 시스템 탐색, 빌드 프로세스 관리 등의 작업을 더욱 자연스럽게 수행할 수 있습니다.

### 보안 고려사항

실험적 기능인 만큼 프로덕션 환경에서는 신중하게 사용해야 합니다. 안전 장치가 마련되어 있지만, LLM에게 시스템 명령어 실행 권한을 부여하는 것은 여전히 위험 요소를 내포하고 있습니다. 개발자들은 허용 목록과 차단 목록을 프로젝트별로 세심하게 설정하고, 중요한 작업에서는 항상 대화형 승인을 활성화해야 합니다.

### 활용 가능한 시나리오

이 기능은 다음과 같은 시나리오에서 특히 유용할 수 있습니다:

- 자연어로 복잡한 Git 작업 수행
- 프로젝트 구조 분석 및 리팩토링 제안
- 자동화된 테스트 및 빌드 실행
- 로그 파일 분석 및 디버깅 지원

ollama 0.14-rc2는 [GitHub](https://github.com/ollama/ollama/releases/tag/v0.14.0-rc2)에서 다운로드할 수 있습니다.

> <a href="https://www.phoronix.com/news/ollama-0.14-rc2" target="_blank" rel="noopener noreferrer">원문 기사 보기</a>